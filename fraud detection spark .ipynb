{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e29a94-b9ef-4587-bc99-29da5211d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20e8101-1e78-492e-b602-ef89445df908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702d5323-39bf-4c75-a6c7-b3ce7b465223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35025194-0136-4de5-bc7e-2e680c632e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/vboxuser/spark-3.5.0-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f43bbd-8211-49ef-a85c-75c70fb3d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Session\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c6ae83-4b46-407b-9238-f201c6f491d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/14 20:49:58 WARN Utils: Your hostname, Ubuntu resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/12/14 20:49:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/14 20:49:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Creating Session\n",
    "spark_session = SparkSession.builder.appName('Fraud Detection').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138b05ff-e574-4b7d-9881-50807da2d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "PartDRawData =\"/home/vboxuser/utkarsh datasets/PartD_Prescriber_PUF_NPI_DRUG_15/PartD_Prescriber_PUF_NPI_Drug_15.txt\"\n",
    "partD_pd = spark_session.read.csv(PartDRawData, header=True, inferSchema=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410f8c4d-05ce-40a3-acf6-3ac7e8db09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=================================================>       (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 24524894\n",
      "Number of Columns: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the number of rows\n",
    "num_rows = partD_pd.count()\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "\n",
    "# Show the number of columns\n",
    "num_columns = len(partD_pd.columns)\n",
    "print(f\"Number of Columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e01423-2644-40ee-a55e-973b18b668ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns\n",
    "partD_Drug_pd1 = partD_pd.select('npi', 'nppes_provider_city', 'nppes_provider_state',\n",
    "                          'nppes_provider_last_org_name', 'nppes_provider_first_name',\n",
    "                          'specialty_description', 'drug_name', 'generic_name',\n",
    "                          'total_drug_cost', 'total_claim_count', 'total_day_supply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e834c8ab-cd36-480a-8ddd-8759950aa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_pd1 = partD_Drug_pd1.alias(\"partD_pd1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5badec76-29fd-405a-b883-3908d57c97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "partD_Drug_pd = partD_pd.select('npi', 'drug_name', 'total_drug_cost', 'total_claim_count', 'total_day_supply', 'specialty_description')\n",
    "\n",
    "# Convert 'npi' column to object type\n",
    "partD_Drug_pd = partD_Drug_pd.withColumn('npi', col('npi').cast('string'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f95d300-ad92-4b28-b508-42c538b4541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_Spec_pd1 = partD_pd.select(\n",
    "    col('npi'),\n",
    "    col('specialty_description')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fef5f63-bc8b-472e-841c-68f5339c26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:========================================>                (17 + 7) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (24524894, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "num_rows = partD_Spec_pd1.count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(partD_Spec_pd1.columns)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(\"Shape of the DataFrame: ({}, {})\".format(num_rows, num_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f16fbf1-3fc1-4505-87bb-ed4e6ab52128",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_pd0 = partD_pd.select(\n",
    "    col('npi'),\n",
    "    col('nppes_provider_city'),\n",
    "    col('nppes_provider_state'),\n",
    "    col('nppes_provider_last_org_name'),\n",
    "    col('nppes_provider_first_name'),\n",
    "    col('specialty_description')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70fbea75-a7b7-42e9-8e63-5ad0cedb1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_catfpd = partD_pd0.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5fc6209-4b16-479b-881b-28dc199e0074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:======================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----+----------+----------+--------------------------------------------------------------+\n",
      "|npi       |city         |state|last_name |first_name|Speciality                                                    |\n",
      "+----------+-------------+-----+----------+----------+--------------------------------------------------------------+\n",
      "|1003013384|LITTLE ROCK  |AR   |OSLEBER   |MICHAEL   |Dermatology                                                   |\n",
      "|1003020538|BRIGHTON     |MA   |BROWN     |COLLEEN   |Physician Assistant                                           |\n",
      "|1003040031|DALLAS       |TX   |GUTTIKONDA|SANDEEP   |Emergency Medicine                                            |\n",
      "|1003063918|SAN FRANCISCO|CA   |AKLILU    |EPHRAIM   |Student in an Organized Health Care Education/Training Program|\n",
      "|1003088550|MORGANTOWN   |WV   |SOFKA     |SARAH     |Internal Medicine                                             |\n",
      "+----------+-------------+-----+----------+----------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rename_dict = {'nppes_provider_first_name': 'first_name', 'nppes_provider_last_org_name': 'last_name',\n",
    "               'nppes_provider_city': 'city', 'nppes_provider_state': 'state', 'specialty_description': 'Speciality'}\n",
    "\n",
    "for old_name, new_name in rename_dict.items():\n",
    "    partD_catfpd = partD_catfpd.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "# Show the first few rows of the new DataFrame\n",
    "partD_catfpd.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8678a8fc-dfaf-4ff5-b357-5014e8cb7f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npi',\n",
       " 'nppes_provider_city',\n",
       " 'nppes_provider_state',\n",
       " 'nppes_provider_last_org_name',\n",
       " 'nppes_provider_first_name',\n",
       " 'specialty_description',\n",
       " 'drug_name',\n",
       " 'generic_name',\n",
       " 'total_drug_cost',\n",
       " 'total_claim_count',\n",
       " 'total_day_supply']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partD_pd1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63434ccf-2481-4bbc-992e-d8135ab47aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "# Define group columns\n",
    "group_cols = ['npi']\n",
    "\n",
    "\n",
    "# Use expr to define aggregations\n",
    "partD_pd2 = partD_pd1.groupBy(group_cols).agg(\n",
    "    expr('SUM(CAST(total_drug_cost AS DOUBLE)) AS total_drug_cost_sum'),\n",
    "    expr('AVG(CAST(total_drug_cost AS DOUBLE)) AS total_drug_cost_mean'),\n",
    "    expr('MAX(CAST(total_drug_cost AS DOUBLE)) AS total_drug_cost_max'),\n",
    "    expr('SUM(CAST(total_claim_count AS INT)) AS total_claim_count_sum'),\n",
    "    expr('AVG(CAST(total_claim_count AS DOUBLE)) AS total_claim_count_mean'),\n",
    "    expr('MAX(CAST(total_claim_count AS INT)) AS total_claim_count_max'),\n",
    "    expr('SUM(CAST(total_day_supply AS INT)) AS total_day_supply_sum'),\n",
    "    expr('AVG(CAST(total_day_supply AS DOUBLE)) AS total_day_supply_mean'),\n",
    "    expr('MAX(CAST(total_day_supply AS INT)) AS total_day_supply_max')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3c3d18-cb97-438c-914b-47fc6ee45a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npi',\n",
       " 'total_drug_cost_sum',\n",
       " 'total_drug_cost_mean',\n",
       " 'total_drug_cost_max',\n",
       " 'total_claim_count_sum',\n",
       " 'total_claim_count_mean',\n",
       " 'total_claim_count_max',\n",
       " 'total_day_supply_sum',\n",
       " 'total_day_supply_mean',\n",
       " 'total_day_supply_max']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partD_pd2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961c2217-c8bf-4fe0-a00d-8d25efb3d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 866552\n",
      "Number of columns: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "num_rows = partD_pd2.count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_cols = len(partD_pd2.columns)\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "811d1a80-499a-4e81-9fe4-da8157be0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_fpd = (\n",
    "    partD_pd2\n",
    "    .withColumnRenamed('sum_total_drug_cost', 'total_drug_cost_sum')\n",
    "    .withColumnRenamed('mean_total_drug_cost', 'total_drug_cost_mean')\n",
    "    .withColumnRenamed('max_total_drug_cost', 'total_drug_cost_max')\n",
    "    .withColumnRenamed('sum_total_claim_count', 'total_claim_count_sum')\n",
    "    .withColumnRenamed('mean_total_claim_count', 'total_claim_count_mean')\n",
    "    .withColumnRenamed('max_total_claim_count', 'total_claim_count_max')\n",
    "    .withColumnRenamed('sum_total_day_supply', 'total_day_supply_sum')\n",
    "    .withColumnRenamed('mean_total_day_supply', 'total_day_supply_mean')\n",
    "    .withColumnRenamed('max_total_day_supply', 'total_day_supply_max')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f284b6f4-5058-4fe3-8a7d-d1b9e33a7a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npi',\n",
       " 'total_drug_cost_sum',\n",
       " 'total_drug_cost_mean',\n",
       " 'total_drug_cost_max',\n",
       " 'total_claim_count_sum',\n",
       " 'total_claim_count_mean',\n",
       " 'total_claim_count_max',\n",
       " 'total_day_supply_sum',\n",
       " 'total_day_supply_mean',\n",
       " 'total_day_supply_max']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partD_fpd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87482418-cc07-45aa-8a97-edfd2c9312c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npi',\n",
       " 'total_drug_cost_sum',\n",
       " 'total_drug_cost_mean',\n",
       " 'total_drug_cost_max',\n",
       " 'total_claim_count_sum',\n",
       " 'total_claim_count_mean',\n",
       " 'total_claim_count_max',\n",
       " 'total_day_supply_sum',\n",
       " 'total_day_supply_mean',\n",
       " 'total_day_supply_max']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partD_fpd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3511a0e4-d25a-4f4e-9143-9eea6da99107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:===================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in partD_fpd: 866552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Assuming partD_fpd is your PySpark DataFrame\n",
    "row_count = partD_fpd.count()\n",
    "print(f\"Number of rows in partD_fpd: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df1a6715-c358-42d4-b818-38633fce125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_allpd = partD_fpd.join(partD_catfpd, on='npi', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a674b673-c272-4fce-a53f-8fa881449012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npi',\n",
       " 'total_drug_cost_sum',\n",
       " 'total_drug_cost_mean',\n",
       " 'total_drug_cost_max',\n",
       " 'total_claim_count_sum',\n",
       " 'total_claim_count_mean',\n",
       " 'total_claim_count_max',\n",
       " 'total_day_supply_sum',\n",
       " 'total_day_supply_mean',\n",
       " 'total_day_supply_max',\n",
       " 'city',\n",
       " 'state',\n",
       " 'last_name',\n",
       " 'first_name',\n",
       " 'Speciality']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partD_allpd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68c4f137-96ab-4f07-9994-23d8c6a8dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PaymentRawData  = \"/home/vboxuser/utkarsh datasets/PGYR15_P012023/OP_DTL_GNRL_PGYR2015_P01202023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fdefccb-0ee5-4691-89db-5ae24b2b5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "payment_pd = spark_session.read.csv(PaymentRawData, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bb47663-c219-48d6-ba7f-b01c744edf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Physician_First_Name='DAVID', Physician_Last_Name='GORDLEY', Recipient_City='SLIPPERY ROCK', Recipient_State='PA', Total_Amount_of_Payment_USDollars='60.00')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_fpd = payment_pd.select(\n",
    "    col('Physician_First_Name'),\n",
    "    col('Physician_Last_Name'),\n",
    "    col('Recipient_City'),\n",
    "    col('Recipient_State'),\n",
    "    col('Total_Amount_of_Payment_USDollars')\n",
    ")\n",
    "payment_fpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5754d448-d063-4332-8e69-67a2097d8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "from pyspark.sql.types import FloatType \n",
    "payment_fpd1 = payment_pd.groupBy(\n",
    "    'Physician_First_Name',\n",
    "    'Physician_Last_Name',\n",
    "    'Recipient_City',\n",
    "    'Recipient_State'\n",
    ").agg(\n",
    "    sum('Total_Amount_of_Payment_USDollars').alias('Total_Amount_of_Payment_USDollars_sum')\n",
    ")\n",
    "\n",
    "# Cast the sum column to float\n",
    "payment_fpd1 = payment_fpd1.withColumn(\n",
    "    'Total_Amount_of_Payment_USDollars_sum',\n",
    "    payment_fpd1['Total_Amount_of_Payment_USDollars_sum'].cast(FloatType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dc2d501-52a2-46d5-8926-b9caafae9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "payment_fpd1 = payment_fpd1.select(\n",
    "    F.col('Physician_First_Name').alias('first_name'),\n",
    "    F.col('Physician_Last_Name').alias('last_name'),\n",
    "    F.col('Recipient_City').alias('city'),\n",
    "    F.col('Recipient_State').alias('state'),\n",
    "    F.col('Total_Amount_of_Payment_USDollars_sum').alias('Total_Payment_Sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a92c6500-6950-429e-85ae-71c6c5f4485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_fpd2 = payment_fpd1.withColumn('index', F.monotonically_increasing_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33f50365-212b-410c-988f-07216bc0ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_fpd2 = payment_fpd2.withColumnRenamed('Physician_First_Name', 'first_name') \\\n",
    "                           .withColumnRenamed('Physician_Last_Name', 'last_name') \\\n",
    "                           .withColumnRenamed('Recipient_City', 'city') \\\n",
    "                           .withColumnRenamed('Recipient_State', 'state') \\\n",
    "                           .withColumnRenamed('Total_Amount_of_Payment_USDollars_sum', 'Total_Payment_Sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0424a292-4794-45fe-8557-7cd251937582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'Total_Payment_Sum' column in descending order\n",
    "payment_fpd2 = payment_fpd2.orderBy('Total_Payment_Sum', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "685a6645-0f8d-4fa4-9537-a8d281eaa663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(first_name=None, last_name=None, city='DUARTE', state='CA', Total_Payment_Sum=306541824.0, index=60129572416)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_fpd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a71cf061-a5a6-44fd-b9d3-644d04e37313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through columns and apply uppercase transformation to string columns\n",
    "for col_name in payment_fpd2.columns:\n",
    "    if payment_fpd2.schema[col_name].dataType == 'string':\n",
    "        payment_fpd2 = payment_fpd2.withColumn(col_name, upper(col(col_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb2a6e69-32ba-4f79-95d9-15c131bf554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partD_alias = partD_allpd.alias('partD')\n",
    "payment_alias = payment_fpd2.alias('payment')\n",
    "\n",
    "# Join using aliases and specify the join conditions\n",
    "pay_partD_fpd = partD_alias.join(\n",
    "    payment_alias,\n",
    "    (col('partD.last_name') == col('payment.last_name')) &\n",
    "    (col('partD.first_name') == col('payment.first_name')) &\n",
    "    (col('partD.city') == col('payment.city')) &\n",
    "    (col('partD.state') == col('payment.state')),\n",
    "    'left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ddc0a2c3-c382-41a3-9949-dc91618b1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "IELErawdata = \"/home/vboxuser/utkarsh datasets/UPDATED.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a52c2a2d-56c4-4534-bccb-92212836be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "IELE_pd = spark_session.read.csv(IELErawdata, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af162ecb-2622-4520-89d3-db61bd6ec0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "npifraud_pd0 = IELE_pd.select(\"NPI\", \"EXCLTYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8024db57-5c75-4451-a174-465963e08912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'NPI' is not equal to 0\n",
    "npifraud_pd1 = npifraud_pd0.filter(col(\"NPI\") != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3770fe13-7b76-44e0-9543-d7fba268999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_fraud_pd = npifraud_pd1.withColumnRenamed(\"NPI\", \"npi\").withColumnRenamed(\"EXCLTYPE\", \"is_fraud\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63d0c321-815e-4e13-aa2d-a80abf9a5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "npi_fraud_pd = npi_fraud_pd.withColumn('is_fraud', lit(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "433b20a1-dfd6-4ee5-8697-75ae86fefc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[NPI: bigint, is_fraud: int]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "npi_fraud_pd.withColumn('NPI', regexp_replace(col('NPI'), '[^0-9]', ''))\n",
    "\n",
    "# Convert to LongType\n",
    "npi_fraud_pd.withColumn('NPI', col('NPI').cast('long'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53cb2ed8-77dc-41ce-ac96-9fdf1ac32d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_pd1 = pay_partD_fpd.join(npi_fraud_pd, on='npi', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80c30803-5bb1-40da-bead-66d5c55f7318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features_pd1.where(Features_pd1.is_fraud.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bf9f4a60-67e8-4c65-8779-bfd6b5a3f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd = Features_pd1.na.fill(value=0,subset=['is_fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c2e87637-6323-4452-ab83-c7516ed2fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(npi=1003043209, total_drug_cost_sum=47219.94000000001, total_drug_cost_mean=1311.6650000000002, total_drug_cost_max=11136.75, total_claim_count_sum=1209, total_claim_count_mean=33.583333333333336, total_claim_count_max=96, total_day_supply_sum=43661, total_day_supply_mean=1212.8055555555557, total_day_supply_max=3998, city='LYNN', state='MA', last_name='AFFEL', first_name='MARJORIE', Speciality='Family Practice', first_name=None, last_name=None, city=None, state=None, Total_Payment_Sum=None, index=None, is_fraud=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0532bdad-1d38-4f29-8f81-0bba3d567252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pd.filter(col('is_fraud') == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5c690eb9-51ff-43c5-a101-db71f75b50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['total_drug_cost_sum', 'total_drug_cost_mean', 'total_drug_cost_max', 'total_claim_count_sum', 'total_claim_count_mean', 'total_claim_count_max', \n",
    " 'total_day_supply_sum', 'total_day_supply_mean', 'total_day_supply_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44b525c7-6cb2-4fd2-be75-224d120d9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'label' is your target column\n",
    "label_column = 'is_fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9ced4e2b-33fb-4a43-abe5-40622a29f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "705a4101-d5b3-4c1e-9822-f4fc2e5c6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd1 = final_pd.select('total_drug_cost_sum', 'total_drug_cost_mean', 'total_drug_cost_max', 'total_claim_count_sum', 'total_claim_count_mean', 'total_claim_count_max', \n",
    " 'total_day_supply_sum', 'total_day_supply_mean', 'total_day_supply_max', 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4216e52-7960-487b-af63-5ec9426afc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data = assembler.transform(final_pd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f3a6414-7ccf-42f5-90b4-a103a17e04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Load data\n",
    "training = assembled_data.select(\"is_fraud\", \"features\")\n",
    "\n",
    "# Create a GBT (Gradient-Boosted Trees) classifier\n",
    "gbt = GBTClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9798557-f2d1-4059-8ed9-f97300208c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(is_fraud=0, features=DenseVector([47219.94, 1311.665, 11136.75, 1209.0, 33.5833, 96.0, 43661.0, 1212.8056, 3998.0]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bb301319-8ab2-4878-9723-56183f56a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "gbt_model = gbt.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "acbe6d5b-1771-405b-aadc-3c58feb10971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/14 22:36:19 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "[Stage 544:============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981871222209657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = gbt_model.transform(training)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
